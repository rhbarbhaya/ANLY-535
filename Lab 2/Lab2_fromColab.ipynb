{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2\n",
        "### 1/23/2022\n",
        "\n",
        "Question 1: A Keras code is provided for running hand written recognition on both GPU and CPU. Run the code on colab and your own machine and compare the results. \\\n",
        "Solution \\\n",
        "\n",
        "| Name        | Local       | Colab         |\n",
        "| :---        |    :----:   |          ---: |\n",
        "| Rushabh     | 502.69 sec  | 89.10 sec     |\n",
        "| Paragraph   | Text        | And more      |\n",
        "||||\n",
        "||||\n",
        "||||\n",
        "||||\n",
        "\n",
        "Question 2: Explain the way that this model is designed. Talk about all the layers and their functionality. \\\n",
        "Solution"
      ],
      "metadata": {
        "id": "C0dQzeRzqs_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSP99695znXi",
        "outputId": "43351dde-08a1-4476-ff2f-4d1ba2085e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show System RAM Memory:\n",
            "\n",
            "\n",
            "MemTotal:       13302920 kB\n",
            "\n",
            "\n",
            "Show Devices:\n",
            "\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10553209576085495562\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14465892352\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 2845353318215413900\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(\"Show System RAM Memory:\\n\\n\")\n",
        "!cat /proc/meminfo | egrep \"MemTotal*\"\n",
        "print(\"\\n\\nShow Devices:\\n\\n\"+str(device_lib.list_local_devices()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d-Pn_V5e0RVm",
        "outputId": "7234c8c5-a4ed-4df0-bba0-43d5dc31a26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ7ZRONV09Gs",
        "outputId": "a95eb332-795b-4953-a9f8-44b580cd5fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "%run \"/content/gdrive/MyDrive/mnist_cnn.py\"\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfsDPhAl3nHX",
        "outputId": "c064c27f-c9c4-4359-b07e-021b5bd1115f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 6s 9ms/step - loss: 0.2850 - accuracy: 0.9111 - val_loss: 0.0643 - val_accuracy: 0.9829\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0927 - accuracy: 0.9722 - val_loss: 0.0465 - val_accuracy: 0.9872\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.0436 - val_accuracy: 0.9880\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0547 - accuracy: 0.9834 - val_loss: 0.0419 - val_accuracy: 0.9872\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0458 - accuracy: 0.9852 - val_loss: 0.0426 - val_accuracy: 0.9882\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.0385 - val_accuracy: 0.9900\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.0439 - val_accuracy: 0.9891\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0404 - val_accuracy: 0.9886\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0426 - val_accuracy: 0.9889\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0373 - val_accuracy: 0.9912\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.0388 - val_accuracy: 0.9905\n",
            "Test loss: 0.029178595170378685\n",
            "Test accuracy: 0.9921000003814697\n",
            "83.83416414260864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "!python3 \"/content/gdrive/MyDrive/mnist_cnn.py\"\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlJX9gMc1JtG",
        "outputId": "51f6f86e-9c09-4335-bc8f-e0d270bb900a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "2022-01-23 21:26:48.850380: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 14s 9ms/step - loss: 0.2794 - accuracy: 0.9146 - val_loss: 0.0647 - val_accuracy: 0.9832\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0946 - accuracy: 0.9714 - val_loss: 0.0473 - val_accuracy: 0.9858\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0685 - accuracy: 0.9787 - val_loss: 0.0440 - val_accuracy: 0.9875\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.0391 - val_accuracy: 0.9884\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.0400 - val_accuracy: 0.9892\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.0366 - val_accuracy: 0.9899\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.0359 - val_accuracy: 0.9899\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0378 - val_accuracy: 0.9893\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0311 - accuracy: 0.9899 - val_loss: 0.0374 - val_accuracy: 0.9902\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.0355 - val_accuracy: 0.9896\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0403 - val_accuracy: 0.9901\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0420 - val_accuracy: 0.9902\n",
            "Test loss: 0.033147938549518585\n",
            "Test accuracy: 0.9918000102043152\n",
            "89.09554958343506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "Xh1p6mcc11PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        " x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        " x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        " input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        " x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        " x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        " input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xprmE4Pg18ue",
        "outputId": "96bae4d1-41bc-4d2b-8f8a-554d5fa735ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the way that this model is designed. Talk about all the layers and their functionality."
      ],
      "metadata": {
        "id": "R4No951yt1DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = baseline()\n",
        "model = model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_test, y_test), epochs=epochs, verbose=2, validation_split=0.2)\n",
        "score = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "vCLFDp7x2LLd",
        "outputId": "c5188fdd-9ab5-460e-b414-da86a29cd158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "375/375 - 6s - loss: 0.2693 - accuracy: 0.9187 - val_loss: 0.0647 - val_accuracy: 0.9802 - 6s/epoch - 17ms/step\n",
            "Epoch 2/12\n",
            "375/375 - 6s - loss: 0.0961 - accuracy: 0.9714 - val_loss: 0.0493 - val_accuracy: 0.9858 - 6s/epoch - 15ms/step\n",
            "Epoch 3/12\n",
            "375/375 - 6s - loss: 0.0687 - accuracy: 0.9793 - val_loss: 0.0458 - val_accuracy: 0.9868 - 6s/epoch - 15ms/step\n",
            "Epoch 4/12\n",
            "375/375 - 5s - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.0416 - val_accuracy: 0.9887 - 5s/epoch - 15ms/step\n",
            "Epoch 5/12\n",
            "375/375 - 5s - loss: 0.0475 - accuracy: 0.9849 - val_loss: 0.0422 - val_accuracy: 0.9882 - 5s/epoch - 15ms/step\n",
            "Epoch 6/12\n",
            "375/375 - 5s - loss: 0.0408 - accuracy: 0.9868 - val_loss: 0.0383 - val_accuracy: 0.9898 - 5s/epoch - 15ms/step\n",
            "Epoch 7/12\n",
            "375/375 - 6s - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.0373 - val_accuracy: 0.9900 - 6s/epoch - 15ms/step\n",
            "Epoch 8/12\n",
            "375/375 - 5s - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.0340 - val_accuracy: 0.9909 - 5s/epoch - 15ms/step\n",
            "Epoch 9/12\n",
            "375/375 - 5s - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0401 - val_accuracy: 0.9897 - 5s/epoch - 15ms/step\n",
            "Epoch 10/12\n",
            "375/375 - 6s - loss: 0.0275 - accuracy: 0.9911 - val_loss: 0.0363 - val_accuracy: 0.9913 - 6s/epoch - 15ms/step\n",
            "Epoch 11/12\n",
            "375/375 - 6s - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0390 - val_accuracy: 0.9904 - 6s/epoch - 15ms/step\n",
            "Epoch 12/12\n",
            "375/375 - 6s - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0378 - val_accuracy: 0.9903 - 6s/epoch - 15ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b304a50ead04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Design the learning curve and talk about what you see. \\\n",
        "Solution: \\"
      ],
      "metadata": {
        "id": "IQTmFb8TuzaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model.history['accuracy'])\n",
        "plt.plot(model.history['val_loss'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('accurary')\n",
        "plt.ylabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')"
      ],
      "metadata": {
        "id": "2KjiCQ-jtx3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/amazon_cells_labelled.txt', names=['sentence', 'label'], sep='\\t')\n",
        "print(df.iloc[0])\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "sentences = ['John likes ice cream', 'John hates chocolate.']\n",
        "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "vectorizer.fit(sentences)\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.transform(sentences).toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCGteasgvPy-",
        "outputId": "f4843800-f984-4b20-f0c4-94ceabfc16c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence    So there is no way for me to plug it in here i...\n",
            "label                                                       0\n",
            "Name: 0, dtype: object\n",
            "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}\n",
            "[[1 0 1 0 1 1]\n",
            " [1 1 0 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "sentences = df['sentence'].values\n",
        "y = df['label'].values\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences_train)\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test = vectorizer.transform(sentences_test)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVGhMpWf2EAS",
        "outputId": "aa0d37da-7669-462d-a726-ea940b4a9918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<750x1546 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 6817 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "score = classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6uhVi-P2Q_Y",
        "outputId": "db3aa615-b0da-488e-b945-75665f10fb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.transform(sentences_train).toarray()\n",
        "X_test = vectorizer.transform(sentences_test).toarray()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "input_dim = X_train.shape[1] # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
        "metrics=['accuracy'])\n",
        "hist = model.fit(X_train, y_train, epochs=100, validation_split=0.2 ,\n",
        "batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Test Accuracy: \",accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH-P-Onk2UDI",
        "outputId": "b8143c66-0e51-4e50-923a-f8d37c66b6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 7ms/step - loss: 0.6881 - accuracy: 0.5850 - val_loss: 0.6772 - val_accuracy: 0.6600\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.8167 - val_loss: 0.6435 - val_accuracy: 0.7467\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.9050 - val_loss: 0.5912 - val_accuracy: 0.7933\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.9267 - val_loss: 0.5387 - val_accuracy: 0.8133\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.9600 - val_loss: 0.4980 - val_accuracy: 0.8333\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.9700 - val_loss: 0.4662 - val_accuracy: 0.8400\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2421 - accuracy: 0.9800 - val_loss: 0.4401 - val_accuracy: 0.8533\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.1966 - accuracy: 0.9833 - val_loss: 0.4274 - val_accuracy: 0.8267\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9883 - val_loss: 0.4138 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9933 - val_loss: 0.4077 - val_accuracy: 0.8400\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9967 - val_loss: 0.4011 - val_accuracy: 0.8333\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9967 - val_loss: 0.3971 - val_accuracy: 0.8333\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9967 - val_loss: 0.3956 - val_accuracy: 0.8333\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8267\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.8267\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8400\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8400\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8400\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.8333\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8400\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.8400\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.8400\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8400\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.8400\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.8400\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.8400\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8400\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8400\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.8400\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.8400\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.8400\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8400\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.8400\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8400\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.8400\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.8400\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8400\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.8400\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.8400\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.8400\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8400\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.8333\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8333\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.8333\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8333\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8333\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8267\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8333\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8333\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8267\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8267\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.8267\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8267\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8267\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.8267\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8267\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8200\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.8200\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8200\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8200\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8200\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.8200\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.8200\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8200\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.7676e-04 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8200\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.3514e-04 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.8200\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.9736e-04 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.8200\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.6002e-04 - accuracy: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.8200\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.2504e-04 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.8267\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.9174e-04 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8267\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 7.5947e-04 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.8267\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.2851e-04 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8267\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.9938e-04 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.8267\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 6.7143e-04 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8267\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.4546e-04 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.8267\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 6.1911e-04 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.8267\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.9556e-04 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8267\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.7232e-04 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8267\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.5092e-04 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.8267\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.2823e-04 - accuracy: 1.0000 - val_loss: 0.5625 - val_accuracy: 0.8267\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.0828e-04 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8267\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.8852e-04 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.8267\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.6959e-04 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.8267\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.5212e-04 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.8267\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.3535e-04 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 0.8267\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.1822e-04 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.8267\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.0246e-04 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.8267\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.8745e-04 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8267\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.7272e-04 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8267\n",
            "Test Accuracy:  77.99999713897705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Explain these graphs. If you see any issue, suggest a solution to resolve it. Make the model by creating 3 hidden layers (first one 200 nodes, second one 100 nodes and last one 50 nodes and after each step, add dropout of 0.2 and report the accuracy. If you don’t see a huge improvement, don’t worry we are not done with the model yet. \\\n",
        "Solution: \\"
      ],
      "metadata": {
        "id": "Mw2ZATRJ3aCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # Adding 1 because of reserved 0 index\n",
        "print(sentences_train[3])\n",
        "print(X_train[3])\n",
        "\n",
        "for word in ['the', 'all', 'happy']:\n",
        " print('{}: {}'.format(word, tokenizer.word_index[word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwAQUN4z3gUs",
        "outputId": "39e21ee0-1c33-4d6c-b6bd-d229ed6a2623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the phone to get for 2005.... I just bought my S710a and all I can say is WOW!\n",
            "[7, 5, 1, 9, 8, 92, 11, 676, 2, 59, 101, 10, 677, 3, 32, 2, 71, 225, 5, 449]\n",
            "the: 1\n",
            "all: 32\n",
            "happy: 86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = 100\n",
        "# Pad variables with zeros \n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "print(X_train[0, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14LktdNc5KpD",
        "outputId": "a12b5021-b59a-498e-fd67-e3fea0bff508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  7  24   5  16   4 137 148   6 223 315   2  71 224   8   1 673 111 444\n",
            "  18 316  11 445   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "embedding_dim = 50\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size,\n",
        " output_dim=embedding_dim,\n",
        " input_length=maxlen))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRbWO_r25ONq",
        "outputId": "e3225c12-9f92-4484-86e1-5e50f6531125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           78700     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 50)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,221\n",
            "Trainable params: 79,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB1ZOJpd5SaT",
        "outputId": "47d41f72-3909-457e-a6e2-bf06b934b89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.6903 - accuracy: 0.6250 - val_loss: 0.6842 - val_accuracy: 0.6867\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.6624 - accuracy: 0.8833 - val_loss: 0.6553 - val_accuracy: 0.7400\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.9200 - val_loss: 0.5916 - val_accuracy: 0.7933\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.9417 - val_loss: 0.5147 - val_accuracy: 0.8133\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3138 - accuracy: 0.9533 - val_loss: 0.4582 - val_accuracy: 0.8133\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2023 - accuracy: 0.9733 - val_loss: 0.4237 - val_accuracy: 0.8333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1300 - accuracy: 0.9800 - val_loss: 0.4018 - val_accuracy: 0.8333\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9883 - val_loss: 0.3866 - val_accuracy: 0.8333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9967 - val_loss: 0.3756 - val_accuracy: 0.8467\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9967 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9983 - val_loss: 0.3711 - val_accuracy: 0.8400\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.8267\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.8267\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.8133\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.8133\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8133\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.8067\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.8133\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8133\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.8067\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.8067\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8067\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8067\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8067\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8067\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8133\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 9.6024e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.8133\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 8.6633e-04 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.8133\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.8333e-04 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.8133\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 7.2624e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.8133\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 6.5510e-04 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.8133\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 5.9724e-04 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8133\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 5.4675e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8133\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.0230e-04 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8133\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.6341e-04 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.8133\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 4.2874e-04 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8133\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 3.9690e-04 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8133\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.6787e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.8133\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.4233e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.8133\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 3.1838e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.8133\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 2.9678e-04 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8133\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 2.7762e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8133\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 2.5984e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8133\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.4321e-04 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.8133\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 2.2814e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8133\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1385e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8133\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.0145e-04 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.8133\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.8939e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8133\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.7847e-04 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.8133\n",
            "Accuracy:  0.7919999957084656\n"
          ]
        }
      ]
    }
  ]
}