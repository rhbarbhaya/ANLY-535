{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knLIzlVJy5xm",
        "outputId": "60b48640-45e8-4fdf-f335-2e91437dbfe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show System RAM Memory:\n",
            "\n",
            "\n",
            "MemTotal:       13302920 kB\n",
            "\n",
            "\n",
            "Show Devices:\n",
            "\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 16547341160210465649\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11320098816\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 2411453900885105868\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "\n",
        "print(\"Show System RAM Memory:\\n\\n\") \n",
        "\n",
        "!cat /proc/meminfo | egrep \"MemTotal*\" \n",
        "\n",
        "print(\"\\n\\nShow Devices:\\n\\n\"+str(device_lib.list_local_devices()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EwK0RHw5cv66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzvWv9jQ0rBH",
        "outputId": "31845aae-5ef3-471c-b328-3543e8128c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "\n",
        "start = time.time() \n",
        "\n",
        "!python3 \"/content/gdrive/MyDrive/ANLY 535/mnist_cnn.py\" \n",
        "\n",
        "end = time.time() \n",
        "\n",
        "print(end - start)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw-7lr5n0rJK",
        "outputId": "6c558edf-408a-4db1-c216-e0dc2083ca6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "2022-01-30 18:59:06.033399: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Epoch 1/12\n",
            "375/375 [==============================] - 15s 16ms/step - loss: 0.2648 - accuracy: 0.9211 - val_loss: 0.0688 - val_accuracy: 0.9800\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0927 - accuracy: 0.9723 - val_loss: 0.0494 - val_accuracy: 0.9858\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.0672 - accuracy: 0.9789 - val_loss: 0.0454 - val_accuracy: 0.9868\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.0530 - accuracy: 0.9842 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 0.0403 - val_accuracy: 0.9895\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.0424 - val_accuracy: 0.9891\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.0358 - accuracy: 0.9883 - val_loss: 0.0381 - val_accuracy: 0.9893\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0386 - val_accuracy: 0.9890\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.0371 - val_accuracy: 0.9907\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0368 - val_accuracy: 0.9906\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0368 - val_accuracy: 0.9906\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0368 - val_accuracy: 0.9908\n",
            "Test loss: 0.029383959248661995\n",
            "Test accuracy: 0.9911999702453613\n",
            "90.73904633522034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import mnist \n",
        "\n",
        "from tensorflow.keras.models import Sequential \n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
        "\n",
        "from tensorflow.keras import backend as K \n",
        "\n",
        "batch_size = 128 \n",
        "\n",
        "num_classes = 10 \n",
        "\n",
        "epochs = 12 \n",
        "\n",
        "# input image dimensions \n",
        "\n",
        "img_rows, img_cols = 28, 28 \n",
        "\n",
        "# the data, split between train and test sets \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "aI8xaCpu5geF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first': \n",
        "\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
        "\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
        "\n",
        "  input_shape = (1, img_rows, img_cols) \n",
        "\n",
        "else: \n",
        "\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) \n",
        "\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) \n",
        "\n",
        "  input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "F1l-vAyY5gkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') \n",
        "\n",
        "x_test = x_test.astype('float32') \n",
        "\n",
        "x_train /= 255 \n",
        "\n",
        "x_test /= 255 \n",
        "\n",
        "print('x_train shape:', x_train.shape) \n",
        "\n",
        "print(x_train.shape[0], 'train samples') \n",
        "\n",
        "print(x_test.shape[0], 'test samples') \n",
        "\n",
        "# convert class vectors to binary class matrices \n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes) \n",
        "\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnLN-o_K0rXQ",
        "outputId": "47b19780-09ee-4842-8ad0-3ba763fd19b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "HW-oWRy26sNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2- Explain the way that this model is designed. Talk about all the layers and their functionality.\n",
        "#The batch size is 128 and epochs is 12. The input data is 28 X 28 pixels. The data is split between test and training dataset. The CNN model has sequential layers, the first layer is input layer with 3 by 3 kernel size andrelu activation. Second layer is convolutional with relu activation. Third layer is a pooling layer which returns themaximum value in pool. The model has 0.25 dropout. \n",
        "#Next layer is a hidden layer. Last layer is fully connectedlayer which generates a classification output."
      ],
      "metadata": {
        "id": "BnJpOMvS6sXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "nn_fit = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=2,validation_split=0.2)\n",
        "score = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "tAPovL4G6shU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33365a4-2c11-48dd-f048-bca0ae3e7fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "375/375 - 11s - loss: 0.2646 - accuracy: 0.9185 - val_loss: 0.0631 - val_accuracy: 0.9818 - 11s/epoch - 28ms/step\n",
            "Epoch 2/12\n",
            "375/375 - 6s - loss: 0.0909 - accuracy: 0.9726 - val_loss: 0.0470 - val_accuracy: 0.9858 - 6s/epoch - 17ms/step\n",
            "Epoch 3/12\n",
            "375/375 - 6s - loss: 0.0673 - accuracy: 0.9797 - val_loss: 0.0440 - val_accuracy: 0.9868 - 6s/epoch - 15ms/step\n",
            "Epoch 4/12\n",
            "375/375 - 5s - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.0419 - val_accuracy: 0.9882 - 5s/epoch - 14ms/step\n",
            "Epoch 5/12\n",
            "375/375 - 5s - loss: 0.0448 - accuracy: 0.9865 - val_loss: 0.0450 - val_accuracy: 0.9879 - 5s/epoch - 14ms/step\n",
            "Epoch 6/12\n",
            "375/375 - 5s - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.0402 - val_accuracy: 0.9889 - 5s/epoch - 14ms/step\n",
            "Epoch 7/12\n",
            "375/375 - 5s - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.0449 - val_accuracy: 0.9868 - 5s/epoch - 14ms/step\n",
            "Epoch 8/12\n",
            "375/375 - 7s - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0409 - val_accuracy: 0.9894 - 7s/epoch - 18ms/step\n",
            "Epoch 9/12\n",
            "375/375 - 7s - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.0368 - val_accuracy: 0.9893 - 7s/epoch - 18ms/step\n",
            "Epoch 10/12\n",
            "375/375 - 6s - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0419 - val_accuracy: 0.9893 - 6s/epoch - 16ms/step\n",
            "Epoch 11/12\n",
            "375/375 - 6s - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0412 - val_accuracy: 0.9901 - 6s/epoch - 15ms/step\n",
            "Epoch 12/12\n",
            "375/375 - 6s - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0411 - val_accuracy: 0.9904 - 6s/epoch - 16ms/step\n",
            "313/313 - 1s - loss: 0.0295 - accuracy: 0.9919 - 1s/epoch - 4ms/step\n",
            "Test loss: 0.02948959358036518\n",
            "Test accuracy: 0.9919000267982483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3- Design the learning curve and talk about what you see.\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(\"Baseline Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "metadata": {
        "id": "f1Vp56Y96sr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40d06d8-f875-4a05-f4e3-93b2dea6d53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0295 - accuracy: 0.9919 - 1s/epoch - 5ms/step\n",
            "Baseline Error: 0.81%\n",
            "Baseline Accuracy: 99.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(nn_fit.history['accuracy'])\n",
        "plt.plot(nn_fit.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(nn_fit.history['loss'])\n",
        "plt.plot(nn_fit.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "#The first graph shows the model accuracy of each epoch, the second graph shows the model loss for eachepoch. Training data is more accurate than test data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BMwTVmm8aQRh",
        "outputId": "dfbb3551-2195-441b-d823-bf115274dfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/ANLY 535/amazon_cells_labelled.txt',names=['sentence', 'label'], sep='\\t')"
      ],
      "metadata": {
        "id": "S2DB8yP8aQns"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print\n",
        "(\n",
        "df.iloc[0])"
      ],
      "metadata": {
        "id": "zEL19-kyaQrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2dfd69-e445-4d60-bb6b-455b618a996c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence    So there is no way for me to plug it in here i...\n",
              "label                                                       0\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['John likes ice cream', 'John hates chocolate.']"
      ],
      "metadata": {
        "id": "pKizyo1-aQua"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "vectorizer.fit(sentences)\n",
        "vectorizer.vocabulary_\n"
      ],
      "metadata": {
        "id": "eiQJeielaQxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3418c6a-cb3d-446f-ca59-669044937f3a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'John': 0, 'chocolate': 1, 'cream': 2, 'hates': 3, 'ice': 4, 'likes': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.transform(sentences).toarray()"
      ],
      "metadata": {
        "id": "WLFRSLPAaQ1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bc8838-9ac8-4d41-86f9-c2435a009c84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0, 1, 1],\n",
              "       [1, 1, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "sentences = df['sentence'].values\n",
        "y = df['label'].values\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "hSC-_LIfqg1A"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences_train)\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test = vectorizer.transform(sentences_test)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7m9co3Kqg9O",
        "outputId": "f00f690a-3799-4bf0-ab34-ff4994f73ede"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<750x1546 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 6817 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "score = classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5IYD-McqhCb",
        "outputId": "700ac7fc-aff9-4a15-d17a-1e9480a18d3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = vectorizer.transform(sentences_train).toarray()\n",
        "X_test = vectorizer.transform(sentences_test).toarray()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "input_dim = X_train.shape[1] # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "hist = model.fit(X_train, y_train, epochs=100, validation_split=0.2 ,batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Test Accuracy: \",accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6m-MEWDrLrC",
        "outputId": "a1061f5f-268f-471c-c19a-6def42a199df"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 7ms/step - loss: 0.6846 - accuracy: 0.5917 - val_loss: 0.6744 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.8317 - val_loss: 0.6450 - val_accuracy: 0.7800\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.9017 - val_loss: 0.6000 - val_accuracy: 0.8133\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.9433 - val_loss: 0.5484 - val_accuracy: 0.8267\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.9583 - val_loss: 0.5046 - val_accuracy: 0.8400\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.9733 - val_loss: 0.4710 - val_accuracy: 0.8400\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2519 - accuracy: 0.9783 - val_loss: 0.4447 - val_accuracy: 0.8467\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2036 - accuracy: 0.9900 - val_loss: 0.4251 - val_accuracy: 0.8533\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1663 - accuracy: 0.9900 - val_loss: 0.4133 - val_accuracy: 0.8533\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.9967 - val_loss: 0.4042 - val_accuracy: 0.8600\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 0.1147 - accuracy: 0.9967 - val_loss: 0.3963 - val_accuracy: 0.8600\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9983 - val_loss: 0.3914 - val_accuracy: 0.8533\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9983 - val_loss: 0.3910 - val_accuracy: 0.8533\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8600\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.8600\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.8600\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.8467\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8467\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8467\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.8467\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.8467\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8467\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.8467\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8533\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 1s 10ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.8467\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8467\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8467\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.8467\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8467\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.8467\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.8533\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8600\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 1s 10ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8600\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8600\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8600\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8600\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.8600\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8600\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8600\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.8600\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8600\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.8600\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8600\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8533\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.8600\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.8600\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8600\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.8600\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8533\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.8600\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.8533\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8533\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8600\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8533\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.8533\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.8533\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8533\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.8600\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8600\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8600\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8533\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.8533\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8533\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.8533\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8600\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8533\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8533\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8600\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.8600\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8533\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8600\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.8600\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.8600\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.8600\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.8575e-04 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8600\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.4416e-04 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.8600\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.0441e-04 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.8600\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 8.6757e-04 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.8600\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 8.3158e-04 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.8600\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 7.9682e-04 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8600\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 7.6483e-04 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8600\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 7.3378e-04 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8600\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 7.0317e-04 - accuracy: 1.0000 - val_loss: 0.5383 - val_accuracy: 0.8600\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 6.7490e-04 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.8600\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 6.4791e-04 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8600\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 6.2375e-04 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.8600\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.9719e-04 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8600\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.7292e-04 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.8600\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.5112e-04 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.2962e-04 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.8600\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.0845e-04 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.8600\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 4.8868e-04 - accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.8600\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 4.7071e-04 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.8600\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 4.5207e-04 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.8600\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.3486e-04 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.8600\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 4.1846e-04 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.0248e-04 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.8600\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.8715e-04 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.8600\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.7194e-04 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.8600\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.5808e-04 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.8600\n",
            "Test Accuracy:  78.39999794960022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "tfG1EpXTrLxw",
        "outputId": "6452fab1-e2fa-46a5-c258-97c812757b4f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4- Explain these graphs. If you see any issue, suggest a solution to resolve it. Make the model by creating 3hidden layers (first one 200 nodes, second one 100 nodes and last one 50 nodes and after each step, adddropout of 0.2 and report the accuracy. If you don’t see a huge improvement, don’t worry we are not done withthe model yet.\n",
        "After around 15 epoch, the loss increases, indicating overfitting, may add regularization such as dropout to fix it."
      ],
      "metadata": {
        "id": "oQfetmvosVaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(layers.Dense(200, input_dim=input_dim, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(layers.Dense(50, input_dim=input_dim, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(layers.Dense(1, activation='sigmoid'))\n",
        "model_2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "hist_2 = model_2.fit(X_train, y_train, epochs=100, validation_split=0.2 ,batch_size=10)\n",
        "loss, accuracy = model_2.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Test Accuracy: \",accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuMeqvkOqhHV",
        "outputId": "e7574e67-03ad-4c2b-b072-396d705e3cf5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 2s 13ms/step - loss: 0.6835 - accuracy: 0.5917 - val_loss: 0.6509 - val_accuracy: 0.7133\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.4676 - accuracy: 0.8417 - val_loss: 0.4677 - val_accuracy: 0.8133\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.9667 - val_loss: 0.5140 - val_accuracy: 0.8133\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 0.0233 - accuracy: 0.9967 - val_loss: 0.5971 - val_accuracy: 0.8067\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.8333\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6086 - val_accuracy: 0.8267\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.8200\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.8267\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 9.1720e-04 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8267\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 7.8372e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8267\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 7.4320e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8267\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 4.8433e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8400\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 3.6191e-04 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8333\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 4.4713e-04 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.8400\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 2.7374e-04 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8467\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 1.8409e-04 - accuracy: 1.0000 - val_loss: 0.7375 - val_accuracy: 0.8400\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 2.1385e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8400\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.8404e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8400\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1150e-04 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.8400\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1944e-04 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.8400\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.7479e-05 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.8467\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0071e-04 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.8400\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.7112e-05 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.8467\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.6658e-05 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.8333\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1494e-04 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.8333\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.9544e-05 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.4904e-05 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.8333\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.1030e-05 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.6131e-05 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.8835e-05 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.2999e-05 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.8333\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.3556e-05 - accuracy: 1.0000 - val_loss: 0.8393 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.0279e-05 - accuracy: 1.0000 - val_loss: 0.8432 - val_accuracy: 0.8333\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1181e-04 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.8267\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.8183e-05 - accuracy: 1.0000 - val_loss: 0.9544 - val_accuracy: 0.8133\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 6.1007e-05 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8467\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1539e-05 - accuracy: 1.0000 - val_loss: 0.9234 - val_accuracy: 0.8467\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.0069e-05 - accuracy: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.8467\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.4253e-05 - accuracy: 1.0000 - val_loss: 0.9401 - val_accuracy: 0.8467\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.0747e-05 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.8467\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.2524e-05 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.8467\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3114e-05 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.8467\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1577e-05 - accuracy: 1.0000 - val_loss: 0.9506 - val_accuracy: 0.8467\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.0084e-05 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.8467\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.6032e-05 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.8467\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1007e-05 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.8467\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 1.7808e-05 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.8467\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 2.4309e-05 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.8467\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.3280e-05 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.8467\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.7279e-05 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.8467\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.9036e-06 - accuracy: 1.0000 - val_loss: 0.9812 - val_accuracy: 0.8467\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2856e-05 - accuracy: 1.0000 - val_loss: 0.9854 - val_accuracy: 0.8467\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0591e-05 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.8467\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.6441e-06 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.8467\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 1.5376e-05 - accuracy: 1.0000 - val_loss: 0.9957 - val_accuracy: 0.8467\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.0377e-06 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.8467\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.2613e-06 - accuracy: 1.0000 - val_loss: 1.0019 - val_accuracy: 0.8467\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.9674e-06 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.8467\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.8186e-06 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.8467\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 5.7519e-06 - accuracy: 1.0000 - val_loss: 1.0122 - val_accuracy: 0.8467\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 1.3124e-05 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.8292e-06 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.8400\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0621e-05 - accuracy: 1.0000 - val_loss: 1.0328 - val_accuracy: 0.8400\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.1919e-06 - accuracy: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.8400\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 8.5315e-06 - accuracy: 1.0000 - val_loss: 1.0329 - val_accuracy: 0.8400\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.2184e-06 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.8400\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 4.5720e-06 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.2584e-06 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.8400\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.3575e-06 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.6438e-06 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.8467\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.9139e-06 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.8467\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.9125e-06 - accuracy: 1.0000 - val_loss: 1.0491 - val_accuracy: 0.8467\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.9794e-06 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.8467\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.0745e-06 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.8400\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 4.6560e-06 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.8400\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 3.5497e-06 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.8400\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.1533e-06 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.8467\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.9014e-06 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.8467\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.6246e-05 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.8533\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.3913e-06 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.8533\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.7310e-06 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.8467\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.5314e-06 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.8600\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.5569e-06 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.8600\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.6701e-06 - accuracy: 1.0000 - val_loss: 1.1230 - val_accuracy: 0.8600\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.6685e-06 - accuracy: 1.0000 - val_loss: 1.1230 - val_accuracy: 0.8600\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.6034e-06 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.8533\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.8483e-06 - accuracy: 1.0000 - val_loss: 1.1295 - val_accuracy: 0.8533\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.6181e-06 - accuracy: 1.0000 - val_loss: 1.1321 - val_accuracy: 0.8533\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.3247e-06 - accuracy: 1.0000 - val_loss: 1.1404 - val_accuracy: 0.8533\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.1489e-06 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.8533\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.0143e-06 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.8533\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.1777e-06 - accuracy: 1.0000 - val_loss: 1.1532 - val_accuracy: 0.8533\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.6387e-06 - accuracy: 1.0000 - val_loss: 1.1533 - val_accuracy: 0.8600\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.7219e-06 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.8533\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.7019e-06 - accuracy: 1.0000 - val_loss: 1.1576 - val_accuracy: 0.8533\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.1554e-07 - accuracy: 1.0000 - val_loss: 1.1644 - val_accuracy: 0.8533\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.7260e-06 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.8533\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 9.9986e-07 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.8533\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 1.5882e-06 - accuracy: 1.0000 - val_loss: 1.1705 - val_accuracy: 0.8533\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.4152e-06 - accuracy: 1.0000 - val_loss: 1.1749 - val_accuracy: 0.8533\n",
            "Test Accuracy:  81.19999766349792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # Adding 1 because of reserved 0 index\n",
        "print(sentences_train[3])\n",
        "print(X_train[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L38qP2AqhKP",
        "outputId": "72bfd99c-502b-4a5a-cd4e-b5950091e430"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the phone to get for 2005.... I just bought my S710a and all I can say is WOW!\n",
            "[7, 5, 1, 9, 8, 92, 11, 676, 2, 59, 101, 10, 677, 3, 32, 2, 71, 225, 5, 449]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in ['the', 'all', 'happy']:print('{}: {}'.format(word, tokenizer.word_index[word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1hkqpqKqhPL",
        "outputId": "eb1481ed-0448-4752-ad72-34e850e2debc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the: 1\n",
            "all: 32\n",
            "happy: 86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = 100\n",
        "# Pad variables with zeros\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "print(X_train[0, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gChTiZQ4qhSB",
        "outputId": "b3c2b2d1-ac83-49e9-bc05-8532d9f93429"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  7  24   5  16   4 137 148   6 223 315   2  71 224   8   1 673 111 444\n",
            "  18 316  11 445   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "embedding_dim = 50\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=maxlen))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
        "metrics=['accuracy' ] )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-s1h7rCqhVW",
        "outputId": "be2bc965-8313-4bd6-fae6-645b878de21f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           78700     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 50)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,221\n",
            "Trainable params: 79,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train,\n",
        "epochs=50,\n",
        "validation_split=0.2,\n",
        "batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Accuracy: \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q2_mLEQupIF",
        "outputId": "2fe8f543-e2c6-4b70-d856-f5de27173164"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "60/60 [==============================] - 2s 13ms/step - loss: 0.6917 - accuracy: 0.5917 - val_loss: 0.6886 - val_accuracy: 0.6333\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.6789 - accuracy: 0.6367 - val_loss: 0.6746 - val_accuracy: 0.6133\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.6432 - accuracy: 0.8217 - val_loss: 0.6385 - val_accuracy: 0.7067\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.5557 - accuracy: 0.9117 - val_loss: 0.5762 - val_accuracy: 0.7200\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.9433 - val_loss: 0.5089 - val_accuracy: 0.7733\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 0.2946 - accuracy: 0.9700 - val_loss: 0.4448 - val_accuracy: 0.8067\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.1876 - accuracy: 0.9783 - val_loss: 0.4023 - val_accuracy: 0.8200\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 0.9883 - val_loss: 0.3774 - val_accuracy: 0.8333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.0675 - accuracy: 0.9917 - val_loss: 0.3656 - val_accuracy: 0.8267\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.0435 - accuracy: 0.9967 - val_loss: 0.3619 - val_accuracy: 0.8533\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9983 - val_loss: 0.3635 - val_accuracy: 0.8400\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.8533\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8600\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.8667\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8533\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.8600\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.8600\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.8600\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8600\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.8600\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.8667\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8667\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.8667\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.8667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.8667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.8667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8667\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.8667\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8600\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8600\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 9.4757e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.8600\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 8.6616e-04 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.8600\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.9421e-04 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8600\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 7.3156e-04 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8600\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 6.7476e-04 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.8600\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 6.2342e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8600\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.7828e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.8600\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.3615e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8600\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 4.9830e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8533\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.6347e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8467\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.3250e-04 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8467\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 4.0381e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8467\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 3.7714e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8467\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.5341e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8467\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.3136e-04 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.8467\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.1123e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8467\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.9252e-04 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.8467\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.7560e-04 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.8467\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.5928e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.8467\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.4459e-04 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.8533\n",
            "Accuracy:  0.7960000038146973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(2,1,1)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7F0f9vHrupQE",
        "outputId": "f5d280bc-dbbb-421f-f774-768b49b6e668"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5- How do you interpret these results?\n",
        "The accuracy is higher than the previous model, but is it still showing overfitting.\n",
        "Q6- What is your recommendation to improve the accuracy? Implement your idea.\n",
        "We should add dropout and more epoches to the model."
      ],
      "metadata": {
        "id": "-sLaR9KLvPZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50\n",
        "model_3 = Sequential()\n",
        "model_3.add(layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=maxlen))\n",
        "model_3.add(layers.GlobalMaxPool1D())\n",
        "model_3.add(layers.Dense(10, activation='relu'))\n",
        "model_3.add(Dropout(0.15))\n",
        "model_3.add(layers.Dense(1, activation='sigmoid'))\n",
        "model_3.add(Dropout(0.15))\n",
        "model_3.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model_3.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcPTRVQsupV9",
        "outputId": "8be25d3d-8ee1-4467-8184-bf05f258beb4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 50)           78700     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 50)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,221\n",
            "Trainable params: 79,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_3 = model_3.fit(X_train, y_train,\n",
        "epochs=100,\n",
        "validation_split=0.2,\n",
        "batch_size=10)\n",
        "loss, accuracy = model_3.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Accuracy: \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lXI4LrMupZs",
        "outputId": "25750829-317d-4e60-aed4-776ae5f2aaf6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 2s 23ms/step - loss: 1.9015 - accuracy: 0.4850 - val_loss: 0.6863 - val_accuracy: 0.5133\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 1s 10ms/step - loss: 1.9310 - accuracy: 0.5500 - val_loss: 0.6694 - val_accuracy: 0.5867\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 1.5434 - accuracy: 0.7433 - val_loss: 0.6176 - val_accuracy: 0.7600\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 1.6722 - accuracy: 0.8200 - val_loss: 0.5516 - val_accuracy: 0.7800\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 1.3594 - accuracy: 0.8817 - val_loss: 0.4896 - val_accuracy: 0.7933\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 1.4420 - accuracy: 0.8867 - val_loss: 0.4441 - val_accuracy: 0.8200\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 1s 9ms/step - loss: 1.1510 - accuracy: 0.9017 - val_loss: 0.4184 - val_accuracy: 0.8267\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 1.3892 - accuracy: 0.9000 - val_loss: 0.3977 - val_accuracy: 0.8133\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.9821 - accuracy: 0.9217 - val_loss: 0.3798 - val_accuracy: 0.8667\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9260 - accuracy: 0.9350 - val_loss: 0.3770 - val_accuracy: 0.8467\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.3059 - accuracy: 0.9083 - val_loss: 0.3729 - val_accuracy: 0.8400\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1927 - accuracy: 0.9167 - val_loss: 0.3792 - val_accuracy: 0.8467\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0538 - accuracy: 0.9333 - val_loss: 0.3707 - val_accuracy: 0.8533\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3296 - accuracy: 0.9150 - val_loss: 0.3756 - val_accuracy: 0.8400\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2538 - accuracy: 0.9200 - val_loss: 0.3861 - val_accuracy: 0.8200\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.8094 - accuracy: 0.9483 - val_loss: 0.3885 - val_accuracy: 0.8200\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1407 - accuracy: 0.9267 - val_loss: 0.3843 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.5252 - accuracy: 0.9017 - val_loss: 0.3857 - val_accuracy: 0.8267\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1900 - accuracy: 0.9233 - val_loss: 0.3867 - val_accuracy: 0.8200\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9857 - accuracy: 0.9350 - val_loss: 0.3936 - val_accuracy: 0.8200\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0646 - accuracy: 0.9300 - val_loss: 0.4000 - val_accuracy: 0.8200\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2148 - accuracy: 0.9217 - val_loss: 0.3994 - val_accuracy: 0.8200\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0065 - accuracy: 0.9350 - val_loss: 0.4126 - val_accuracy: 0.8200\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9067 - accuracy: 0.9417 - val_loss: 0.4205 - val_accuracy: 0.8200\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.5205 - accuracy: 0.9017 - val_loss: 0.4178 - val_accuracy: 0.8133\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0069 - accuracy: 0.9350 - val_loss: 0.4144 - val_accuracy: 0.8200\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1859 - accuracy: 0.9233 - val_loss: 0.4328 - val_accuracy: 0.8200\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2886 - accuracy: 0.9167 - val_loss: 0.4269 - val_accuracy: 0.8200\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.3661 - accuracy: 0.9117 - val_loss: 0.4367 - val_accuracy: 0.8200\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1598 - accuracy: 0.9250 - val_loss: 0.4362 - val_accuracy: 0.8200\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0052 - accuracy: 0.9350 - val_loss: 0.4264 - val_accuracy: 0.8200\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.9531 - accuracy: 0.9383 - val_loss: 0.4383 - val_accuracy: 0.8267\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0812 - accuracy: 0.9300 - val_loss: 0.4447 - val_accuracy: 0.8200\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1596 - accuracy: 0.9250 - val_loss: 0.4520 - val_accuracy: 0.8200\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0046 - accuracy: 0.9350 - val_loss: 0.4602 - val_accuracy: 0.8200\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1070 - accuracy: 0.9283 - val_loss: 0.4729 - val_accuracy: 0.8267\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2626 - accuracy: 0.9183 - val_loss: 0.4566 - val_accuracy: 0.8267\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0817 - accuracy: 0.9300 - val_loss: 0.4544 - val_accuracy: 0.8333\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0556 - accuracy: 0.9317 - val_loss: 0.4490 - val_accuracy: 0.8333\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.9533 - accuracy: 0.9383 - val_loss: 0.4580 - val_accuracy: 0.8267\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3900 - accuracy: 0.9100 - val_loss: 0.4797 - val_accuracy: 0.8267\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1589 - accuracy: 0.9250 - val_loss: 0.4787 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.4668 - accuracy: 0.9050 - val_loss: 0.4934 - val_accuracy: 0.8333\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1837 - accuracy: 0.9233 - val_loss: 0.4920 - val_accuracy: 0.8333\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1321 - accuracy: 0.9267 - val_loss: 0.4955 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1321 - accuracy: 0.9267 - val_loss: 0.4954 - val_accuracy: 0.8267\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0298 - accuracy: 0.9333 - val_loss: 0.4924 - val_accuracy: 0.8267\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3121 - accuracy: 0.9150 - val_loss: 0.4992 - val_accuracy: 0.8267\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0288 - accuracy: 0.9333 - val_loss: 0.5119 - val_accuracy: 0.8200\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2607 - accuracy: 0.9183 - val_loss: 0.4896 - val_accuracy: 0.8200\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2605 - accuracy: 0.9183 - val_loss: 0.4912 - val_accuracy: 0.8200\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0037 - accuracy: 0.9350 - val_loss: 0.5013 - val_accuracy: 0.8200\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.9217 - val_loss: 0.5144 - val_accuracy: 0.8200\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3632 - accuracy: 0.9117 - val_loss: 0.5150 - val_accuracy: 0.8267\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0807 - accuracy: 0.9300 - val_loss: 0.5001 - val_accuracy: 0.8200\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.8494 - accuracy: 0.9450 - val_loss: 0.4970 - val_accuracy: 0.8200\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2864 - accuracy: 0.9167 - val_loss: 0.5030 - val_accuracy: 0.8200\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9258 - accuracy: 0.9400 - val_loss: 0.5070 - val_accuracy: 0.8200\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0803 - accuracy: 0.9300 - val_loss: 0.5196 - val_accuracy: 0.8133\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1834 - accuracy: 0.9233 - val_loss: 0.5169 - val_accuracy: 0.8133\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1316 - accuracy: 0.9267 - val_loss: 0.5213 - val_accuracy: 0.8133\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.9264 - accuracy: 0.9400 - val_loss: 0.5215 - val_accuracy: 0.8200\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0544 - accuracy: 0.9317 - val_loss: 0.5187 - val_accuracy: 0.8133\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0544 - accuracy: 0.9317 - val_loss: 0.5255 - val_accuracy: 0.8200\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.9773 - accuracy: 0.9367 - val_loss: 0.5208 - val_accuracy: 0.8133\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.8492 - accuracy: 0.9450 - val_loss: 0.5428 - val_accuracy: 0.8200\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1066 - accuracy: 0.9283 - val_loss: 0.5428 - val_accuracy: 0.8200\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3379 - accuracy: 0.9133 - val_loss: 0.5085 - val_accuracy: 0.8200\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.4142 - accuracy: 0.9083 - val_loss: 0.5161 - val_accuracy: 0.8200\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2859 - accuracy: 0.9167 - val_loss: 0.5282 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3887 - accuracy: 0.9100 - val_loss: 0.5379 - val_accuracy: 0.8200\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.8235 - accuracy: 0.9467 - val_loss: 0.5489 - val_accuracy: 0.8200\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2857 - accuracy: 0.9167 - val_loss: 0.5579 - val_accuracy: 0.8200\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1057 - accuracy: 0.9283 - val_loss: 0.5648 - val_accuracy: 0.8200\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2342 - accuracy: 0.9200 - val_loss: 0.5704 - val_accuracy: 0.8200\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3114 - accuracy: 0.9150 - val_loss: 0.5678 - val_accuracy: 0.8200\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2598 - accuracy: 0.9183 - val_loss: 0.5760 - val_accuracy: 0.8267\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.9217 - val_loss: 0.5929 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.9200 - val_loss: 0.6007 - val_accuracy: 0.8267\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2861 - accuracy: 0.9167 - val_loss: 0.6063 - val_accuracy: 0.8267\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1841 - accuracy: 0.9217 - val_loss: 0.6271 - val_accuracy: 0.8267\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.9002 - accuracy: 0.9417 - val_loss: 0.6015 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.8486 - accuracy: 0.9450 - val_loss: 0.6079 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.1570 - accuracy: 0.9250 - val_loss: 0.6143 - val_accuracy: 0.8333\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2342 - accuracy: 0.9200 - val_loss: 0.6166 - val_accuracy: 0.8333\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2856 - accuracy: 0.9167 - val_loss: 0.5920 - val_accuracy: 0.8267\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.3125 - accuracy: 0.9150 - val_loss: 0.5728 - val_accuracy: 0.8267\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1571 - accuracy: 0.9250 - val_loss: 0.5866 - val_accuracy: 0.8200\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1827 - accuracy: 0.9233 - val_loss: 0.5940 - val_accuracy: 0.8200\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2600 - accuracy: 0.9183 - val_loss: 0.6080 - val_accuracy: 0.8200\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.9514 - accuracy: 0.9383 - val_loss: 0.6066 - val_accuracy: 0.8200\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1570 - accuracy: 0.9250 - val_loss: 0.6133 - val_accuracy: 0.8267\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0800 - accuracy: 0.9300 - val_loss: 0.6212 - val_accuracy: 0.8333\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1313 - accuracy: 0.9267 - val_loss: 0.6327 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.2857 - accuracy: 0.9167 - val_loss: 0.6456 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.1570 - accuracy: 0.9250 - val_loss: 0.6306 - val_accuracy: 0.8267\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 1.0299 - accuracy: 0.9317 - val_loss: 0.6125 - val_accuracy: 0.8200\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.0800 - accuracy: 0.9300 - val_loss: 0.6226 - val_accuracy: 0.8200\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2087 - accuracy: 0.9217 - val_loss: 0.6301 - val_accuracy: 0.8133\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.2599 - accuracy: 0.9183 - val_loss: 0.6353 - val_accuracy: 0.8133\n",
            "Accuracy:  0.7960000038146973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell jupyter nbconvert --to html '//content/gdrive/My Drive/Colab Notebooks/Test.ipynb'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzq4G9T1upcm",
        "outputId": "113bc049-f882-4a0f-9f74-ecaf1218fbf6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook //content/gdrive/My Drive/Colab Notebooks/Test.ipynb to html\n",
            "[NbConvertApp] Writing 464636 bytes to //content/gdrive/My Drive/Colab Notebooks/Test.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CFExOI-wupfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z-iqGpWPqhZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}